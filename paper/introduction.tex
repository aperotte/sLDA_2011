The task of multi-label classification, selecting the k-best labels for a given
instance, has been a topic of research for several years. One simplistic way to
carry out the classification is through a series of independent binary
classifiers, but this ignores the many inherent dependencies among the
labels. Thus, much work has been devoted on incorporating the co-occurence
patterns of the labels into the classification task. In this paper, we focus on
multi-label classification, where the labels are organized in a hierarchical
structure. Scenarios of use include, but are not limited to, placing webpages
into manually curated Internet directories~\cite{DMOZ}, categorizing images
according to a taxonomy, tagging product descriptions with catalogue
information~\cite{SNAP}, and assigning diagnosis codes to clinical
records~\cite{Challenge07}.

There are several challenges entailed in incorporating the hierarchical nature
of labels into the classification task. One pertains to the labeling itself: in
the datasets (especially real-world, noisy ones), for a given label, instances
labeled with it contribute positive instance, but it is unclear how to
determine the negative instances. In particular, how to treat the parent labels
of the selected ones? 

Our work operates within the framework of topic modeling. Our approach learns
topic models of the underlying data and labeling strategies in a joint model,
while leveraging the hierarchical structure of the labels. In particular, we
extend supervised latent Dirichlet allocation (sLDA)~\cite{BleiMcAuliffe2008}
to take advantage of hierarchical supervision. We hypothesize that hierarchical
label information provides more information about labeling than considering
labels as a flat list.

We demonstrate our model on large, real-world datasets in the clinical and web
retail domains. We observe that hierarchical information is valuable when
incorporated into the learning and improves our primary goal of multi-label
classification. Following the trend observed in supervised topic modeling, we
note that the learned topic models are more representative of the underlying
data in both of our datasets~\cite{BleiMcAuliffe2008}.

The remainder of this paper is as follows. Section~\ref{sec:model}
introduces hierarchically supervised LDA (HSLDA), while
Section~\ref{sec:inference} details a sampling approach to inference in HSLDA. 
Section~\ref{sec:related_work} reviews related work, and
Section~\ref{sec:experiments} shows results from applying HSLDA to health care
and web retail data.  

%In this paper we describe the use of a topic model based on supervised
%latent Dirichlet allocation (sLDA) to identify topics within narrative
%discharge summaries and to automate the assignment of diagnostic codes,
%specifically International Classification of Disease 9th Revision,
%Clinical Modification (ICD-9-CM) codes. There are a number of advantages
%to this approach. First, manually coding diagnoses is a time-consuming
%and notoriously unreliable process. Many diagnoses are omitted in
%the final record, and a high error rate is found even in the principal
%diagnoses \citep{Surjan1999}.

%Our main contribution is to show how to utilize supervision in the form of
%hierarchical and (often) multiple labelings in a similar manner. Consider web
%retail data. Web retailers often have both a browse-able product hierarchy and
%free-text descriptions for all products they sell. The situation of each
%product in a product hierarchy (often multiply situated) constitutes a
%multiple, hierarchical labeling of the free-text product descriptions. We
%hypothesize that such hierarchical labels should, at least in theory, provide
%better supervision than the simpler unstructured labels previously considered.
%Results from applying our model to both medical record and web retail data
%suggests that this is likely the case. In particular, we observe gains in our
%primary goal of out-of-sample label prediction that result specifically from
%leveraging hierarchical supervision. 

%\begin{itemize}
%\item Benefits of combining human categorization information into ``topic models''
%\item LDA solved free text
%\item supervised LDA improves LDA (extra info) and allows new inference (predict links, etc.)
%\item amazon, freshdirect, netflix, dmoz, pandora (music genome)
%\end{itemize}


% Informatics journal paper
%
% Despite the growing emphasis on meaningful
%use of technology in medicine, many aspects of medical record-keeping
%remain a manual process. Diagnostic coding for billing and insurance
%purposes is often handled by professional medical coders who must
%explore a patient's extensive clinical record before assigning the
%proper codes. So while electronic health records (EHRs) should be
%adopted by most medical institutions within the next several years,
%largely due to the provisions of HITECH under the American Recovery
%and Reinvestment Act \citep{Blumenthal2009}, there has been little
%movement forward in automating medical coding.

%An automated process would ideally produce a more complete and accurate
%diagnosis lists. Also, this model will reveal information about the
%medical records themselves. For example, we may gain an understanding
%of what a specific code actually means in terms of clinical narratives.
%Similarly, viewing the distribution of topics over discharge summaries
%may reveal information about the latent structure of clinician documentation.
%Lastly, the sLDA model would provide a novel approach to dealing with
%the problem of high dimensionality when representing narrative text
%in a vector space specifically by reducing dimensions from an entire
%vocabulary of potentially tens of thousands of words to a set of several
%dozen topics.

